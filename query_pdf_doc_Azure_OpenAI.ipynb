{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOT4Ul1APc9r"
      },
      "source": [
        "Install the required python packages if not already present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JxsoFu2jMHEz"
      },
      "outputs": [],
      "source": [
        "# !pip install gradio\n",
        "# !pip install langchain\n",
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2010oRFTL4uv"
      },
      "outputs": [],
      "source": [
        "# import required packages\n",
        "import gradio as gr\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma, FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import AzureOpenAI\n",
        "import os\n",
        "import openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before executing the next cells, make sure that a valid Azure subscription is available and an instance of Azure OpenAI services is created. \n",
        "\n",
        "Then add the credentials for the Azure API calls in the following manner:\n",
        "\n",
        "```\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2022-12-01\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = #your model endpoint\n",
        "os.environ[\"OPENAI_API_KEY\"] = #your api key\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hesFJUAkL4uz"
      },
      "outputs": [],
      "source": [
        "# define a class with all required methods\n",
        "class App:\n",
        "    def __init__(self) -> None:\n",
        "        self.qa = None\n",
        "    \n",
        "    def load_doc(self, file_obj):\n",
        "        '''Load PDF document and parse by page'''\n",
        "        loader = PyPDFLoader(file_obj.name)\n",
        "        pages = loader.load_and_split()\n",
        "        return pages\n",
        "    \n",
        "    def upload_file(self, file_obj):\n",
        "        '''Handle the upload request'''\n",
        "        pages = self.load_doc(file_obj)\n",
        "        # initialize embeddings\n",
        "        embeddings = OpenAIEmbeddings(chunk_size=1)\n",
        "        # generate embeddings for the uploaded doc\n",
        "        docsearch = FAISS.from_documents(pages, embeddings)\n",
        "        # params\n",
        "        temperature = 0\n",
        "        deployment_name = \"text-davinci-003\"\n",
        "        max_tokens = 500\n",
        "        \n",
        "        llm = AzureOpenAI(temperature=temperature, deployment_name=deployment_name, max_tokens=max_tokens)\n",
        "\n",
        "        # prepare the query answering object\n",
        "        self.qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=docsearch.as_retriever(search_type='mmr'))\n",
        "        # make the subsequent components of the UI visible\n",
        "        return gr.Textbox().update(visible=True), gr.Checkbox.update(visible=True), gr.Button.update(visible=True), gr.Textbox.update(visible=True)\n",
        "\n",
        "    def response_optimizer(self, query_response):\n",
        "        '''Optimize the first response from the model to generate a more interpretable response'''\n",
        "        prompt = f'''Optimize the following text and rephrase it in simpler terms to make it easier to read and interpret. Use bullet points wherever necessary.\n",
        "        \n",
        "        # Text:\n",
        "        {query_response}\n",
        "\n",
        "        # Optimized Text:'''\n",
        "\n",
        "        # langchain is not required for this purpose\n",
        "        openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "        openai.api_base =  os.getenv('OPENAI_API_BASE')\n",
        "        openai.api_type = os.getenv('OPENAI_API_TYPE')\n",
        "        openai.api_version = os.getenv('OPENAI_API_VERSION')\n",
        "        response = openai.Completion.create(engine='text-davinci-003', prompt=prompt, max_tokens= 1000, temperature=0)\n",
        "        response = response['choices'][0]['text']\n",
        "        return response         \n",
        "\n",
        "    def answer_query(self, query):\n",
        "        '''Handle query request and return response'''\n",
        "        query_response = self.qa.run(query)\n",
        "        optimized_response = self.response_optimizer(query_response)\n",
        "        return optimized_response\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IHTFOmfAL4u_"
      },
      "outputs": [],
      "source": [
        "# initialize the function\n",
        "app = App()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "-cAP7g6fL4vA",
        "outputId": "25f27198-1716-437d-e104-b48d96b36f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7860, \"/\", \"100%\", 500, false, window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo = gr.Blocks(theme=gr.themes.Monochrome())\n",
        "\n",
        "with demo:\n",
        "    with gr.Row():\n",
        "        \n",
        "        file1 = gr.File(info = \"upload the policy pdf file\", file_count='single', file_types=['.pdf'])    \n",
        "    upload_btn = gr.Button(\"Upload\")\n",
        "        \n",
        "    with gr.Row():\n",
        "            with gr.Column():\n",
        "                query_text = gr.Textbox(label=\"Enter your question\", interactive=True, visible=False)\n",
        "                process_btn = gr.Button(\"Get Answer\", visible=False)\n",
        "            with gr.Column():\n",
        "                response_text = gr.Textbox(label=\"Response:\", visible=False)\n",
        "    \n",
        "    \n",
        "    upload_btn.click(app.upload_file, inputs=[file1], outputs = [query_text, process_btn, response_text])\n",
        "    process_btn.click(app.answer_query, inputs=[query_text], outputs = [response_text])\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On Successful run of the above cells, we would be able to observe the following user-interface:\n",
        "![img 1](./resources/1.jpg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then upload any pdf file of our choice and wait till the query area appears:\n",
        "![img 2](./resources/2.jpg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![img 3](./resources/3.jpg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now put our query in the text box and click on the \"Get Answer\" button to trigger the API call to the model:\n",
        "![img 4](./resources/4.jpg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model takes a few seconds to process and the result appears on the right-hand side:\n",
        "![img 5](./resources/5.jpg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try another query:\n",
        "![img 6](./resources/6.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cteam8_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
